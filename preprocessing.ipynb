{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stations.pkl', 'rb') as f:\n",
    "    wroclaw_stations = pickle.load(f)\n",
    "wroclaw_stations += ['Fabryczna (WSB)']\n",
    "\n",
    "cols = ['bike_number', 'start_time', 'end_time', 'rental_place', 'return_place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_and_remove_slash(s):\n",
    "    return s.strip().replace('/', '-').replace('\"', '').replace(',', ' -').replace('\\xa0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clear_data(filename):\n",
    "    print(filename)\n",
    "    data = pd.read_csv(filename, usecols=cols)\n",
    "    data['return_place'] = data['return_place'].apply(trim_and_remove_slash)\n",
    "    data['rental_place'] = data['rental_place'].apply(trim_and_remove_slash)\n",
    "    data = data[data.return_place.isin(wroclaw_stations) & data.rental_place.isin(wroclaw_stations)]\n",
    "    data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_longer_than_24(data):\n",
    "    data['rental_time'] = pd.to_timedelta(pd.DatetimeIndex(data['end_time']) - pd.DatetimeIndex(data['start_time']), unit='m')\n",
    "    data = data[data['rental_time'] < pd.to_timedelta(24, unit='h')]\n",
    "    data = data[data['rental_time'] > pd.to_timedelta(1, unit='m')]\n",
    "    return data.drop(columns=['rental_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/historia_przejazdow_2019-11.csv\n",
      "data/historia_przejazdow_2019-12.csv\n",
      "data/historia_przejazdow_2019-03.csv\n",
      "data/historia_przejazdow_2019-07.csv\n",
      "data/historia_przejazdow_2019-08.csv\n",
      "data/historia_przejazdow_2019-06.csv\n",
      "data/historia_przejazdow_2019-09.csv\n",
      "data/historia_przejazdow_2019-04.csv\n",
      "data/historia_przejazdow_2019-10.csv\n",
      "data/historia_przejazdow_2019-05.csv\n"
     ]
    }
   ],
   "source": [
    "data_directory = 'data'\n",
    "preprocessed_directory = 'data_preprocessed'\n",
    "stations = np.array([])\n",
    "os.makedirs(preprocessed_directory, exist_ok=True)\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        data = load_and_clear_data(f'{data_directory}/{filename}')\n",
    "        data = remove_longer_than_24(data)\n",
    "        month_stations = np.concatenate((data['rental_place'].unique(), data['return_place'].unique()))\n",
    "        stations = np.unique(np.concatenate((stations, month_stations)))\n",
    "        data.to_csv(f'{preprocessed_directory}/{filename}_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(stations)\n",
    "for filename in os.listdir(preprocessed_directory):\n",
    "    if filename.endswith('.csv') and filename.startswith('historia'):\n",
    "        data = pd.read_csv(f'{preprocessed_directory}/{filename}')\n",
    "        data['rental_place'] = le.transform(data['rental_place'])\n",
    "        data['return_place'] = le.transform(data['return_place'])\n",
    "        data.to_csv(f'{preprocessed_directory}/{filename}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {stations[i]: i for i in range(0, len(le.classes_))}\n",
    "stations_pd = pd.DataFrame(stations, columns=['name'])\n",
    "stations_pd.index.rename('value')\n",
    "stations_pd.to_csv(f'{preprocessed_directory}/nodes.csv', index=True, index_label='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import lxml.html as lh\n",
    "# import pandas as pd\n",
    "\n",
    "# url='https://wroclawskirower.pl/mapa-stacji/'\n",
    "# page = requests.get(url)\n",
    "# doc = lh.fromstring(page.content)\n",
    "# tr_elements = doc.xpath('//tr')\n",
    "# col=[]\n",
    "# for t in tr_elements[1:]:\n",
    "#     col.append(t[1].text_content())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (wod-bike-dataset-generator)",
   "language": "python",
   "name": "pycharm-a5af7dde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
